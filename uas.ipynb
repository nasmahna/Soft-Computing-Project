{"cells":[{"cell_type":"markdown","metadata":{"id":"QG2EGL6UuNev"},"source":["# IMPORT DEPENDENCIES"]},{"cell_type":"code","execution_count":7,"metadata":{"id":"dUo1_OohuNe1","executionInfo":{"status":"ok","timestamp":1674042794806,"user_tz":-420,"elapsed":14,"user":{"displayName":"Nasmah Nur Amiroh","userId":"01262524895721116745"}}},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","import math\n","import random\n","import operator\n","import matplotlib.pyplot as plt\n","import tensorflow as tf"]},{"cell_type":"code","execution_count":8,"metadata":{"id":"l46R0Bv0uNe3","executionInfo":{"status":"ok","timestamp":1674042794807,"user_tz":-420,"elapsed":13,"user":{"displayName":"Nasmah Nur Amiroh","userId":"01262524895721116745"}}},"outputs":[],"source":["from sklearn.model_selection import train_test_split"]},{"cell_type":"code","execution_count":9,"metadata":{"id":"e6ZrqpnpuNe4","executionInfo":{"status":"ok","timestamp":1674042794807,"user_tz":-420,"elapsed":12,"user":{"displayName":"Nasmah Nur Amiroh","userId":"01262524895721116745"}}},"outputs":[],"source":["from tensorflow.keras.utils import to_categorical"]},{"cell_type":"code","execution_count":10,"metadata":{"id":"wxeQ-Q1euNe4","executionInfo":{"status":"ok","timestamp":1674042794808,"user_tz":-420,"elapsed":12,"user":{"displayName":"Nasmah Nur Amiroh","userId":"01262524895721116745"}}},"outputs":[],"source":["import warnings\n","#suppress warnings\n","warnings.filterwarnings('ignore')"]},{"cell_type":"markdown","metadata":{"id":"iMztv0RKuNe5"},"source":["# EXPLORATORY DATA ANALYSIS"]},{"cell_type":"markdown","metadata":{"id":"X0sSB9nwuNe5"},"source":["## Read Dataset"]},{"cell_type":"code","execution_count":11,"metadata":{"id":"PvgjwBHcuNe6","executionInfo":{"status":"ok","timestamp":1674042794809,"user_tz":-420,"elapsed":12,"user":{"displayName":"Nasmah Nur Amiroh","userId":"01262524895721116745"}}},"outputs":[],"source":["df = pd.read_csv(\"glass.csv\")"]},{"cell_type":"code","execution_count":12,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":424},"id":"5BXWQL9nuNe7","executionInfo":{"status":"ok","timestamp":1674042795562,"user_tz":-420,"elapsed":764,"user":{"displayName":"Nasmah Nur Amiroh","userId":"01262524895721116745"}},"outputId":"f312df8f-5ee0-4371-c790-6c47cb7115f8"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["          RI     Na    Mg    Al     Si     K    Ca    Ba   Fe  Type\n","0    1.52101  13.64  4.49  1.10  71.78  0.06  8.75  0.00  0.0     1\n","1    1.51761  13.89  3.60  1.36  72.73  0.48  7.83  0.00  0.0     1\n","2    1.51618  13.53  3.55  1.54  72.99  0.39  7.78  0.00  0.0     1\n","3    1.51766  13.21  3.69  1.29  72.61  0.57  8.22  0.00  0.0     1\n","4    1.51742  13.27  3.62  1.24  73.08  0.55  8.07  0.00  0.0     1\n","..       ...    ...   ...   ...    ...   ...   ...   ...  ...   ...\n","209  1.51623  14.14  0.00  2.88  72.61  0.08  9.18  1.06  0.0     7\n","210  1.51685  14.92  0.00  1.99  73.06  0.00  8.40  1.59  0.0     7\n","211  1.52065  14.36  0.00  2.02  73.42  0.00  8.44  1.64  0.0     7\n","212  1.51651  14.38  0.00  1.94  73.61  0.00  8.48  1.57  0.0     7\n","213  1.51711  14.23  0.00  2.08  73.36  0.00  8.62  1.67  0.0     7\n","\n","[214 rows x 10 columns]"],"text/html":["\n","  <div id=\"df-f2c5378d-28a6-426e-8448-cf22e0546143\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>RI</th>\n","      <th>Na</th>\n","      <th>Mg</th>\n","      <th>Al</th>\n","      <th>Si</th>\n","      <th>K</th>\n","      <th>Ca</th>\n","      <th>Ba</th>\n","      <th>Fe</th>\n","      <th>Type</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1.52101</td>\n","      <td>13.64</td>\n","      <td>4.49</td>\n","      <td>1.10</td>\n","      <td>71.78</td>\n","      <td>0.06</td>\n","      <td>8.75</td>\n","      <td>0.00</td>\n","      <td>0.0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1.51761</td>\n","      <td>13.89</td>\n","      <td>3.60</td>\n","      <td>1.36</td>\n","      <td>72.73</td>\n","      <td>0.48</td>\n","      <td>7.83</td>\n","      <td>0.00</td>\n","      <td>0.0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>1.51618</td>\n","      <td>13.53</td>\n","      <td>3.55</td>\n","      <td>1.54</td>\n","      <td>72.99</td>\n","      <td>0.39</td>\n","      <td>7.78</td>\n","      <td>0.00</td>\n","      <td>0.0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>1.51766</td>\n","      <td>13.21</td>\n","      <td>3.69</td>\n","      <td>1.29</td>\n","      <td>72.61</td>\n","      <td>0.57</td>\n","      <td>8.22</td>\n","      <td>0.00</td>\n","      <td>0.0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>1.51742</td>\n","      <td>13.27</td>\n","      <td>3.62</td>\n","      <td>1.24</td>\n","      <td>73.08</td>\n","      <td>0.55</td>\n","      <td>8.07</td>\n","      <td>0.00</td>\n","      <td>0.0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>209</th>\n","      <td>1.51623</td>\n","      <td>14.14</td>\n","      <td>0.00</td>\n","      <td>2.88</td>\n","      <td>72.61</td>\n","      <td>0.08</td>\n","      <td>9.18</td>\n","      <td>1.06</td>\n","      <td>0.0</td>\n","      <td>7</td>\n","    </tr>\n","    <tr>\n","      <th>210</th>\n","      <td>1.51685</td>\n","      <td>14.92</td>\n","      <td>0.00</td>\n","      <td>1.99</td>\n","      <td>73.06</td>\n","      <td>0.00</td>\n","      <td>8.40</td>\n","      <td>1.59</td>\n","      <td>0.0</td>\n","      <td>7</td>\n","    </tr>\n","    <tr>\n","      <th>211</th>\n","      <td>1.52065</td>\n","      <td>14.36</td>\n","      <td>0.00</td>\n","      <td>2.02</td>\n","      <td>73.42</td>\n","      <td>0.00</td>\n","      <td>8.44</td>\n","      <td>1.64</td>\n","      <td>0.0</td>\n","      <td>7</td>\n","    </tr>\n","    <tr>\n","      <th>212</th>\n","      <td>1.51651</td>\n","      <td>14.38</td>\n","      <td>0.00</td>\n","      <td>1.94</td>\n","      <td>73.61</td>\n","      <td>0.00</td>\n","      <td>8.48</td>\n","      <td>1.57</td>\n","      <td>0.0</td>\n","      <td>7</td>\n","    </tr>\n","    <tr>\n","      <th>213</th>\n","      <td>1.51711</td>\n","      <td>14.23</td>\n","      <td>0.00</td>\n","      <td>2.08</td>\n","      <td>73.36</td>\n","      <td>0.00</td>\n","      <td>8.62</td>\n","      <td>1.67</td>\n","      <td>0.0</td>\n","      <td>7</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>214 rows Ã— 10 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f2c5378d-28a6-426e-8448-cf22e0546143')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-f2c5378d-28a6-426e-8448-cf22e0546143 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-f2c5378d-28a6-426e-8448-cf22e0546143');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":12}],"source":["df"]},{"cell_type":"code","execution_count":13,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Odv0T7l0uNe9","executionInfo":{"status":"ok","timestamp":1674042795563,"user_tz":-420,"elapsed":16,"user":{"displayName":"Nasmah Nur Amiroh","userId":"01262524895721116745"}},"outputId":"370e9f34-b8c1-4ab2-cbf9-3f0f026309a4"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["RI      0\n","Na      0\n","Mg      0\n","Al      0\n","Si      0\n","K       0\n","Ca      0\n","Ba      0\n","Fe      0\n","Type    0\n","dtype: int64"]},"metadata":{},"execution_count":13}],"source":["df.isna().sum()"]},{"cell_type":"code","execution_count":14,"metadata":{"id":"VqhGnakCuNe-","executionInfo":{"status":"ok","timestamp":1674042795564,"user_tz":-420,"elapsed":13,"user":{"displayName":"Nasmah Nur Amiroh","userId":"01262524895721116745"}}},"outputs":[],"source":["X = df.drop(columns=[\"Type\"], axis=1).copy()\n","y = to_categorical(df[\"Type\"].copy())"]},{"cell_type":"code","execution_count":15,"metadata":{"id":"8GXQhqT3uNe_","executionInfo":{"status":"ok","timestamp":1674042795571,"user_tz":-420,"elapsed":20,"user":{"displayName":"Nasmah Nur Amiroh","userId":"01262524895721116745"}}},"outputs":[],"source":["X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"]},{"cell_type":"markdown","metadata":{"id":"Aqtrdpl5uNe_"},"source":["# NEURAL NETWORK"]},{"cell_type":"code","execution_count":16,"metadata":{"id":"unckatF2uNe_","executionInfo":{"status":"ok","timestamp":1674042795572,"user_tz":-420,"elapsed":20,"user":{"displayName":"Nasmah Nur Amiroh","userId":"01262524895721116745"}}},"outputs":[],"source":["'''\n","Initialize Metric Class\n","'''\n","class Metric:\n","    def rmse(self, prediction, target):\n","        return np.sqrt(np.square(prediction - target).mean())\n","        \n","    def accuracy(self, prediction, target):\n","        return np.equal(prediction, target).sum()/len(prediction)\n","    \n","metric = Metric()"]},{"cell_type":"code","execution_count":17,"metadata":{"id":"Aohy5zXGuNfA","executionInfo":{"status":"ok","timestamp":1674042795573,"user_tz":-420,"elapsed":20,"user":{"displayName":"Nasmah Nur Amiroh","userId":"01262524895721116745"}}},"outputs":[],"source":["class NeuralNetwork:\n","    def __init__(self):\n","        self.layers = list()\n","        self.dimensions = list()\n","        self.weights = list()\n","        \n","    def init(self):\n","        layers = []\n","        for j in range(len(self.dimensions)-1):\n","            shape = (self.dimensions[j],self.dimensions[j+1])\n","            layer = np.random.normal(size=shape)\n","            layers.append(layer)    \n","        self.weights.append(np.array(layers, dtype=object))\n","        \n","    '''\n","    MENAMBAHKAN INPUT LAYER\n","    '''\n","    def addInputLayer(self, shape, activation=\"linear\"):\n","        self.layers.append({ \"units\": shape, \"activation\":activation, \"layer\":\"input\" })\n","        self.dimensions.append(shape)\n","\n","    '''\n","    MENAMBAHKAN LAYER\n","    Penambahan layer paling akhir merupakan output layer\n","    '''\n","    def addLayer(self, units, activation=\"linear\"):\n","        layer = { \"units\": units, \"activation\": activation, \"layer\":\"output\"}\n","        self.layers[len(self.layers)-1][\"layer\"] = \"hidden\"\n","        self.layers.append(layer)\n","        self.dimensions.append(units)\n","            \n","    '''\n","    Mengaktivasi output menggunakan fungsi aktivasi\n","    '''\n","    def activate(self, activation):\n","        activation_func = {\n","            \"sigmoid\" : lambda x: 1/(1+np.exp(-x)),\n","            \"relu\" : lambda x: max(0,x),\n","            \"tanh\" : lambda x: np.tanh(x),\n","            \"linear\" : lambda x: x\n","        }\n","        return activation_func[activation]\n","\n","    '''\n","    Menghitung output dengan feedforward propagation\n","    '''\n","    def feedforward(self, inputs, weights):\n","        inputs = inputs\n","        for L in range(len(self.dimensions)-1):\n","            output = np.matmul(inputs, weights[L])\n","            actv_output = np.array(list(map(self.activate(self.layers[L][\"activation\"]), output)))\n","            inputs = actv_output\n","        return inputs\n","    \n","    '''\n","    Fungsi menghitung fitness individu\n","    '''\n","    def fitness_func(self,weights):\n","\n","        pred_list = []\n","        for train in self.features:\n","            pred = self.feedforward(train, weights)\n","            pred_list.append(pred)\n","\n","            prediction = np.argmax(pred_list, axis=1)\n","            output = np.argmax(self.output, axis=1)\n","            \n","        loss = metric.rmse(prediction, output) # RMSE\n","        accuracy = metric.accuracy(prediction, output)\n","            \n","        return loss, accuracy\n","    \n","    def predict(self, X):\n","        res = list()\n","        for i in X:\n","            res.append(self.feedforward(i, self.weights))\n","        return np.array(res)\n","        \n","    def gradient_descent(self):\n","        pass\n","    \n","    def fit(self, X, y, epochs, lr):\n","        self.features = X\n","        self.output = y\n","        self.lr = lr\n","        \n","        for i in range(epochs):\n","            loss, accuracy = self.fitness_func(self.X, self.weights)\n","            \n","            break\n"]},{"cell_type":"code","execution_count":18,"metadata":{"id":"HYVrQj2muNfB","executionInfo":{"status":"ok","timestamp":1674042795573,"user_tz":-420,"elapsed":19,"user":{"displayName":"Nasmah Nur Amiroh","userId":"01262524895721116745"}}},"outputs":[],"source":["class EvolvingNN(NeuralNetwork):\n","  def __init__(self):\n","    super().__init__()\n","\n","  '''\n","  Membuat populasi awal sesuai dengan jumlah yang ditentukan\n","  '''\n","  def init(self,num_population):\n","    self.population = []\n","    for i in range(num_population):\n","      layers = []\n","      for j in range(len(self.dimensions)-1):\n","        shape = (self.dimensions[j],self.dimensions[j+1])\n","        layer = np.random.normal(size=shape)\n","        layers.append(layer)\n","      self.population.append(np.array(layers, dtype=object))\n","  \n","  '''\n","  Menghitung fitness untuk populasi\n","  Diurutkan, kemudian diambil sebesar elite_percentage\n","  '''\n","  def fitness_population(self,elite_percentage):\n","    new_pop = []\n","    for id_ind in range(len(self.population)):\n","      loss, accuracy = super().fitness_func(self.population[id_ind]) \n","      new_pop.append((loss,accuracy,self.population[id_ind]))\n","    \n","    # selection ambil sesuai elite_percentage\n","    # sorting dengan loss terendah dan acc tertinggi\n","    new_pop.sort(key=operator.itemgetter(0),reverse=False)\n","    # ambil top elite_percentage\n","    select_count = math.floor(len(self.population)*elite_percentage)\n","    self.population = [x[2] for x in new_pop][:select_count]\n","\n","  '''\n","  Memilih berapa banyak terjadi crossover\n","  Kemudian lakukan generate 1 child untuk tiap crossover\n","  '''\n","  def crossover(self,crossover_percentage):\n","    # jumlah pernikahan\n","    number_of_crossover = math.floor(crossover_percentage*len(self.population))\n","    list_parent = random.sample(range(0,len(self.population)),2*number_of_crossover)\n","\n","    for i in range(number_of_crossover):\n","      p1 = self.population[list_parent[i]]\n","      p2 = self.population[list_parent[i+1]]\n","      m = random.random()\n","      \n","      # blend crossover\n","      c = (1-m) * p1 + m * p2\n","      self.population.append(c)\n","\n","  '''\n","  Mutasi yang digunakan gaussian noise\n","  '''\n","  def mutation(self,mutation_percentage):\n","    number_of_mutation = math.floor(mutation_percentage*len(self.population))\n","\n","    for i in range(number_of_mutation):\n","      # ambil individu\n","      idmutate = random.randint(0,len(self.population)-1)\n","      self.population[idmutate] = self.population[idmutate] * np.random.normal(1,1)\n","      \n","\n","  '''\n","  Fitting model Neural Network dengan Genetic Algorithm\n","  '''\n","  def fit(self, X, y, n_pop, n_gen):\n","    self.features = X\n","    self.output = y\n","    \n","    self.init(n_pop)\n","    number_of_iteration = n_gen\n","    losses = []\n","    accuracies = []\n","    for i in range(number_of_iteration):\n","      self.fitness_population(0.8)\n","      \n","      best_pop = self.population[0]\n","      loss, accuracy = super().fitness_func(best_pop)\n","      losses.append(loss)\n","      accuracies.append(accuracy)\n","      \n","      print(\"Generasi ke\",i+1,\"- Jumlah populasi\",len(self.population),\"- RMSE:\",loss,\"- Acc:\",accuracy)\n","\n","      self.crossover(0.5)\n","      self.mutation(0.5)\n","      \n","      self.weights = self.population[0]\n","      \n","      if i == number_of_iteration - 1:\n","        return losses, accuracies\n","\n","    '''Gradient Descent'''\n","    def mean_squared_error(y_true, y_predicted):\n","\t\n","      # Calculating the loss or cost\n","      cost = np.sum((y_true-y_predicted)**2) / len(y_true)\n","      return cost\n","\n","    # Gradient Descent Function\n","    # Here iterations, learning_rate, stopping_threshold\n","    # are hyperparameters that can be tuned\n","    def gradient_descent(x, y, iterations = 1000, learning_rate = 0.0001,\n","              stopping_threshold = 1e-6):\n","      \n","      # Initializing weight, bias, learning rate and iterations\n","      current_weight = 0.1\n","      current_bias = 0.01\n","      iterations = iterations\n","      learning_rate = learning_rate\n","      n = float(len(x))\n","      \n","      costs = []\n","      weights = []\n","      previous_cost = None\n","      \n","      # Estimation of optimal parameters\n","      for i in range(iterations):\n","        \n","        # Making predictions\n","        y_predicted = (current_weight * x) + current_bias\n","        \n","        # Calculating the current cost\n","        current_cost = mean_squared_error(y, y_predicted)\n","\n","        # If the change in cost is less than or equal to\n","        # stopping_threshold we stop the gradient descent\n","        if previous_cost and abs(previous_cost-current_cost)<=stopping_threshold:\n","          break\n","        \n","        previous_cost = current_cost\n","\n","        costs.append(current_cost)\n","        weights.append(current_weight)\n","        \n","        # Calculating the gradients\n","        weight_derivative = -(2/n) * sum(x * (y-y_predicted))\n","        bias_derivative = -(2/n) * sum(y-y_predicted)\n","        \n","        # Updating weights and bias\n","        current_weight = current_weight - (learning_rate * weight_derivative)\n","        current_bias = current_bias - (learning_rate * bias_derivative)\n","            \n","        # Printing the parameters for each 1000th iteration\n","        print(f\"Iteration {i+1}: Cost {current_cost}, Weight \\\n","        {current_weight}, Bias {current_bias}\")\n","      \n","      \n","      # Visualizing the weights and cost at for all iterations\n","      plt.figure(figsize = (8,6))\n","      plt.plot(weights, costs)\n","      plt.scatter(weights, costs, marker='o', color='red')\n","      plt.title(\"Cost vs Weights\")\n","      plt.ylabel(\"Cost\")\n","      plt.xlabel(\"Weight\")\n","      plt.show()\n","      \n","      return current_weight, current_bias\n","\n","\n","    def main():\n","      \n","      # Data\n","      X = np.array([32.50234527, 53.42680403, 61.53035803, 47.47563963, 59.81320787,\n","        55.14218841, 52.21179669, 39.29956669, 48.10504169, 52.55001444,\n","        45.41973014, 54.35163488, 44.1640495 , 58.16847072, 56.72720806,\n","        48.95588857, 44.68719623, 60.29732685, 45.61864377, 38.81681754])\n","      Y = np.array([31.70700585, 68.77759598, 62.5623823 , 71.54663223, 87.23092513,\n","        78.21151827, 79.64197305, 59.17148932, 75.3312423 , 71.30087989,\n","        55.16567715, 82.47884676, 62.00892325, 75.39287043, 81.43619216,\n","        60.72360244, 82.89250373, 97.37989686, 48.84715332, 56.87721319])\n","\n","      # Estimating weight and bias using gradient descent\n","      estimated_weight, estimated_bias = gradient_descent(X, Y, iterations=2000)\n","      print(f\"Estimated Weight: {estimated_weight}\\nEstimated Bias: {estimated_bias}\")\n","\n","      # Making predictions using estimated parameters\n","      Y_pred = estimated_weight*X + estimated_bias\n","\n","      # Plotting the regression line\n","      plt.figure(figsize = (8,6))\n","      plt.scatter(X, Y, marker='o', color='red')\n","      plt.plot([min(X), max(X)], [min(Y_pred), max(Y_pred)], color='blue',markerfacecolor='red',\n","          markersize=10,linestyle='dashed')\n","      plt.xlabel(\"X\")\n","      plt.ylabel(\"Y\")\n","      plt.show()\n","          \n","        "]},{"cell_type":"code","execution_count":19,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nfCfCiZcuNfD","executionInfo":{"status":"ok","timestamp":1674042803439,"user_tz":-420,"elapsed":7884,"user":{"displayName":"Nasmah Nur Amiroh","userId":"01262524895721116745"}},"outputId":"6717bb6b-b798-4f89-ae12-977c1eb46ad4"},"outputs":[{"output_type":"stream","name":"stdout","text":["Generasi ke 1 - Jumlah populasi 40 - RMSE: 2.0576486893187016 - Acc: 0.08187134502923976\n","Generasi ke 2 - Jumlah populasi 48 - RMSE: 2.0576486893187016 - Acc: 0.08187134502923976\n"]}],"source":["evolvingNN = EvolvingNN()\n","evolvingNN.addInputLayer(X.shape[1], activation=\"sigmoid\")\n","evolvingNN.addLayer(10, activation=\"sigmoid\")\n","evolvingNN.addLayer(y.shape[1], activation=\"relu\")\n","\n","n_pop = 50\n","n_gen = 2\n","loss, accuracy = evolvingNN.fit(X_train.values, y_train, n_pop, n_gen)"]},{"cell_type":"code","execution_count":20,"metadata":{"id":"wwOj_lZjuNfD","executionInfo":{"status":"ok","timestamp":1674042803440,"user_tz":-420,"elapsed":18,"user":{"displayName":"Nasmah Nur Amiroh","userId":"01262524895721116745"}}},"outputs":[],"source":["y_pred = evolvingNN.predict(X_test.values)"]},{"cell_type":"code","execution_count":21,"metadata":{"id":"ZF3Kc7aDuNfE","executionInfo":{"status":"ok","timestamp":1674042803441,"user_tz":-420,"elapsed":18,"user":{"displayName":"Nasmah Nur Amiroh","userId":"01262524895721116745"}}},"outputs":[],"source":["y_test_1 = np.argmax(y_test, axis=1)\n","y_pred_1 = np.argmax(y_pred, axis=1)"]},{"cell_type":"code","execution_count":22,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":282},"id":"SCL_AxEOuNfE","executionInfo":{"status":"ok","timestamp":1674042804146,"user_tz":-420,"elapsed":722,"user":{"displayName":"Nasmah Nur Amiroh","userId":"01262524895721116745"}},"outputId":"6cbc571d-f4dd-43fa-d34b-85bb70c4c717"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["[<matplotlib.lines.Line2D at 0x7f8eb4107c10>]"]},"metadata":{},"execution_count":22},{"output_type":"display_data","data":{"text/plain":["<Figure size 432x288 with 1 Axes>"],"image/png":"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\n"},"metadata":{"needs_background":"light"}}],"source":["plt.plot(range(1,len(loss)+1),loss)"]},{"cell_type":"code","execution_count":23,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":282},"id":"vKH29DSquNfF","executionInfo":{"status":"ok","timestamp":1674042804147,"user_tz":-420,"elapsed":35,"user":{"displayName":"Nasmah Nur Amiroh","userId":"01262524895721116745"}},"outputId":"20c47c26-dd9c-4c06-d966-f5a631e1e17c"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["[<matplotlib.lines.Line2D at 0x7f8eb4089ee0>]"]},"metadata":{},"execution_count":23},{"output_type":"display_data","data":{"text/plain":["<Figure size 432x288 with 1 Axes>"],"image/png":"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\n"},"metadata":{"needs_background":"light"}}],"source":["plt.plot(range(1,len(accuracy)+1), accuracy)"]},{"cell_type":"markdown","metadata":{"id":"o8dvnA19uNfF"},"source":["## NEURAL NETWORK GRADIENT DESCENT"]},{"cell_type":"code","execution_count":23,"metadata":{"id":"HbWimg1wuNfG","executionInfo":{"status":"ok","timestamp":1674042804195,"user_tz":-420,"elapsed":79,"user":{"displayName":"Nasmah Nur Amiroh","userId":"01262524895721116745"}}},"outputs":[],"source":["# Importing Libraries\n","import numpy as np\n","import matplotlib.pyplot as plt\n","\n","def mean_squared_error(y_true, y_predicted):\n","\t\n","\t# Calculating the loss or cost\n","\tcost = np.sum((y_true-y_predicted)**2) / len(y_true)\n","\treturn cost\n","\n","# Gradient Descent Function\n","# Here iterations, learning_rate, stopping_threshold\n","# are hyperparameters that can be tuned\n","def gradient_descent(x, y, iterations = 1000, learning_rate = 0.0001,\n","\t\t\t\t\tstopping_threshold = 1e-6):\n","\t\n","\t# Initializing weight, bias, learning rate and iterations\n","\tcurrent_weight = 0.1\n","\tcurrent_bias = 0.01\n","\titerations = iterations\n","\tlearning_rate = learning_rate\n","\tn = float(len(x))\n","\t\n","\tcosts = []\n","\tweights = []\n","\tprevious_cost = None\n","\t\n","\t# Estimation of optimal parameters\n","\tfor i in range(iterations):\n","\t\t\n","\t\t# Making predictions\n","\t\ty_predicted = (current_weight * x) + current_bias\n","\t\t\n","\t\t# Calculating the current cost\n","\t\tcurrent_cost = mean_squared_error(y, y_predicted)\n","\n","\t\t# If the change in cost is less than or equal to\n","\t\t# stopping_threshold we stop the gradient descent\n","\t\tif previous_cost and abs(previous_cost-current_cost)<=stopping_threshold:\n","\t\t\tbreak\n","\t\t\n","\t\tprevious_cost = current_cost\n","\n","\t\tcosts.append(current_cost)\n","\t\tweights.append(current_weight)\n","\t\t\n","\t\t# Calculating the gradients\n","\t\tweight_derivative = -(2/n) * sum(x * (y-y_predicted))\n","\t\tbias_derivative = -(2/n) * sum(y-y_predicted)\n","\t\t\n","\t\t# Updating weights and bias\n","\t\tcurrent_weight = current_weight - (learning_rate * weight_derivative)\n","\t\tcurrent_bias = current_bias - (learning_rate * bias_derivative)\n","\t\t\t\t\n","\t\t# Printing the parameters for each 1000th iteration\n","\t\tprint(f\"Iteration {i+1}: Cost {current_cost}, Weight \\\n","\t\t{current_weight}, Bias {current_bias}\")\n","\t\n","\t\n","\t# Visualizing the weights and cost at for all iterations\n","\tplt.figure(figsize = (8,6))\n","\tplt.plot(weights, costs)\n","\tplt.scatter(weights, costs, marker='o', color='red')\n","\tplt.title(\"Cost vs Weights\")\n","\tplt.ylabel(\"Cost\")\n","\tplt.xlabel(\"Weight\")\n","\tplt.show()\n","\t\n","\treturn current_weight, current_bias\n","\n","\n","def main():\n","\t\n","\t# Data\n","\tX = np.array([32.50234527, 53.42680403, 61.53035803, 47.47563963, 59.81320787,\n","\t\t55.14218841, 52.21179669, 39.29956669, 48.10504169, 52.55001444,\n","\t\t45.41973014, 54.35163488, 44.1640495 , 58.16847072, 56.72720806,\n","\t\t48.95588857, 44.68719623, 60.29732685, 45.61864377, 38.81681754])\n","\tY = np.array([31.70700585, 68.77759598, 62.5623823 , 71.54663223, 87.23092513,\n","\t\t78.21151827, 79.64197305, 59.17148932, 75.3312423 , 71.30087989,\n","\t\t55.16567715, 82.47884676, 62.00892325, 75.39287043, 81.43619216,\n","\t\t60.72360244, 82.89250373, 97.37989686, 48.84715332, 56.87721319])\n","\n","\t# Estimating weight and bias using gradient descent\n","\testimated_weight, estimated_bias = gradient_descent(X, Y, iterations=2000)\n","\tprint(f\"Estimated Weight: {estimated_weight}\\nEstimated Bias: {estimated_bias}\")\n","\n","\t# Making predictions using estimated parameters\n","\tY_pred = estimated_weight*X + estimated_bias\n","\n","\t# Plotting the regression line\n","\tplt.figure(figsize = (8,6))\n","\tplt.scatter(X, Y, marker='o', color='red')\n","\tplt.plot([min(X), max(X)], [min(Y_pred), max(Y_pred)], color='blue',markerfacecolor='red',\n","\t\t\tmarkersize=10,linestyle='dashed')\n","\tplt.xlabel(\"X\")\n","\tplt.ylabel(\"Y\")\n","\tplt.show()\n","\n","\t\n","if __name__==\"__main__\":\n","\tmain()\n"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.0"},"orig_nbformat":4,"vscode":{"interpreter":{"hash":"84c8bcfd3ece7b8d2e9484bf4ce8517a5a4dbcc142a29f247d8a18b531027092"}},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":0}